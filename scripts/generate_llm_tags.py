import os
import sys
import yaml
from google import genai

# --- Configuration ---
POST_TO_PROCESS = os.environ.get('POST_TO_PROCESS')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
SENTINEL_TAG = 'ai-processed'
TAG_KEY = 'tags'

if not POST_TO_PROCESS or not GEMINI_API_KEY:
    print("Error: Environment variables POST_TO_PROCESS and GEMINI_API_KEY must be set.")
    sys.exit(1)

# --- Utility Functions ---

def parse_file(filepath):
    """Loads YAML front matter and content from the Markdown file."""
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()

    # Split the file into YAML front matter and body content
    parts = content.split('---', 2)
    if len(parts) < 3:
        # File is likely corrupted or missing front matter
        raise ValueError("File does not contain valid YAML front matter delimiters (---).")
    
    front_matter_raw = parts[1].strip()
    post_content = parts[2].strip()
    
    front_matter = yaml.safe_load(front_matter_raw)
    return front_matter, post_content

def write_file(filepath, front_matter, post_content):
    """Writes the updated YAML front matter and content back to the file."""
    # Convert dictionary back to YAML string
    yaml_dump = yaml.dump(front_matter, sort_keys=False, default_flow_style=False)
    
    # Reconstruct the file content
    new_content = f"---\n{yaml_dump}---\n\n{post_content}\n"
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(new_content)

def call_llm_for_tags(content):
    """Calls Gemini to generate new tags."""
    try:
        client = genai.Client(api_key=GEMINI_API_KEY)
        
        prompt = (
            "Analyze the blog post content. Generate 5 high-value, "
            "niche, and technical tags (keywords) that best summarize the topic. "
            "Return ONLY the 5 tags separated by commas, with no other surrounding text."
            f"Content (first 3000 chars): {content[:3000]}"
        )
        
        response = client.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt
        )
        
        # Clean the response string (remove spaces, split by comma)
        raw_tags = response.text.strip().lower().split(',')
        cleaned_tags = [tag.strip().replace(' ', '-') for tag in raw_tags if tag.strip()]

        return cleaned_tags

    except Exception as e:
        print(f"Error calling LLM API: {e}")
        # Return an empty list to avoid crashing the workflow
        return []

# --- Main Logic ---

def main():
    try:
        front_matter, post_content = parse_file(POST_TO_PROCESS)
        
        # 1. Check for the Sentinel Tag
        existing_tags = front_matter.get(TAG_KEY, [])
        if SENTINEL_TAG in existing_tags:
            print(f"Post already processed by AI ({SENTINEL_TAG} found). Exiting.")
            sys.exit(0)

        print(f"Processing post: {POST_TO_PROCESS}")
        
        # 2. Call LLM
        new_ai_tags = call_llm_for_tags(post_content)
        
        if not new_ai_tags:
            print("No new tags generated by LLM. Exiting.")
            sys.exit(0)
            
        # 3. Merge and Sanitize
        
        # Add the existing and new tags to a set for unique values
        combined_tags_set = set(existing_tags)
        combined_tags_set.update(new_ai_tags)
        
        # Add the sentinel tag to prevent future processing
        combined_tags_set.add(SENTINEL_TAG)
        
        # Convert back to list and sort (optional, but good practice)
        final_tags_list = sorted(list(combined_tags_set))
        
        # 4. Update and Write File
        front_matter[TAG_KEY] = final_tags_list
        write_file(POST_TO_PROCESS, front_matter, post_content)
        
        print(f"Successfully added {len(new_ai_tags)} tags to the '{TAG_KEY}' field.")

    except Exception as e:
        print(f"A critical error occurred: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
